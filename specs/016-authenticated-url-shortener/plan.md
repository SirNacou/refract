# Implementation Plan: Authenticated URL Shortener Platform

**Branch**: `016-authenticated-url-shortener` | **Date**: 2026-01-09 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/016-authenticated-url-shortener/spec.md`

**Note**: This plan is generated by the `/speckit.plan` command following the Refract Constitution v1.0.0.

## Summary

Build a distributed URL shortener platform where authenticated users can create short URLs and view detailed click analytics. The system uses Zitadel for authentication, Snowflake IDs with Base62 encoding for short codes, multi-tier caching for <50ms redirects, and TimescaleDB for time-series analytics data. The architecture follows Domain-Driven Design with CQRS pattern, comprising three main services: API (URL management), Redirector (high-performance redirects), and Analytics Processor (real-time event aggregation).

**Core User Journeys**:
1. User authenticates via Zitadel (OIDC), creates short URLs with auto-generated or custom aliases
2. Anyone visits short URL → redirected instantly (<50ms p95) with click event captured
3. User views real-time analytics dashboard with geographic, device, referrer, and time-series data
4. Developer generates API key, creates short URLs programmatically via REST API

## Technical Context

**Language/Version**: 
- **Go 1.22+** (API service - CQRS handlers, domain logic, HTTP)
- **Rust 1.75+** (Redirector service - high-performance, low-latency redirects)
- **TypeScript 5.3+** (Frontend - TanStack Start for SSR/SSG)

**Primary Dependencies**:
- **Backend (Go)**: Chi router, OIDC library (go-oidc), SQLc (type-safe queries), go-redis
- **Backend (Rust)**: Axum web framework, SQLx, Redis client, Tokio runtime
- **Frontend**: TanStack Start (React-based), TanStack Query, Recharts (analytics visualizations)
- **Infrastructure**: PostgreSQL 16 + TimescaleDB extension, Redis/Valkey 7.2+, Zitadel (deployed)

**Storage**: 
- **PostgreSQL 16**: User profiles, short URLs, API keys (relational data)
- **TimescaleDB** (PostgreSQL extension): Click events, time-series aggregations (hypertables)
- **Redis/Valkey 7.2+**: L2 distributed cache for redirects, rate limiting counters

**Testing**: 
- **Go**: `go test` with testify, contract tests with httptest
- **Rust**: `cargo test` with integration tests for redirect service
- **Frontend**: Vitest for unit tests, Playwright for E2E

**Target Platform**: 
- **Backend Services**: Linux containers (Docker), deployed on cloud VMs or Kubernetes
- **Frontend**: Edge deployment (Vercel, Cloudflare Pages) or self-hosted Node.js server
- **Databases**: Managed PostgreSQL (AWS RDS, DigitalOcean) or self-hosted with replication

**Project Type**: Web application (distributed microservices + SPA frontend)

**Performance Goals**: 
- **Redirects**: <50ms p95 latency, 10,000 concurrent requests
- **API**: <200ms p95 for URL creation, <100ms p95 for analytics queries
- **Analytics Processing**: <5 second latency from click to dashboard visibility
- **Throughput**: 1M+ redirects per day sustained load

**Constraints**: 
- **Redirect Service**: <50ms p95 latency (hard requirement for user experience)
- **Cache Hit Rate**: >90% for L1+L2 combined (hot URLs must be memory-resident)
- **Analytics Data Volume**: 10M+ events/month, 5-year retention
- **Authentication**: Zero password storage (Zitadel handles all auth flows)
- **Horizontal Scaling**: All services must scale independently without coordination

**Scale/Scope**: 
- **Users**: 10,000 active users initially, 100K growth target
- **URLs**: 500K short URLs (average 50 per user)
- **Click Events**: 10M events/month (20 clicks/URL average)
- **Analytics Queries**: 1,000 queries/hour during peak
- **API Usage**: 10% of users use API keys, 100K API requests/month

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

Verify compliance with Refract Constitution (`.specify/memory/constitution.md`):

- [x] **Domain Layer Isolation** (Principle I): Business logic isolated in domain layer, no framework dependencies
  - URL entity with validation (destination URL, custom alias, expiration)
  - ShortCode value object with Base62 encoding/decoding logic
  - APIKey entity with hashing and validation rules
  - Repository interfaces for URL, APIKey (no implementation details)
  
- [x] **CQRS Separation** (Principle II): Commands (writes) and Queries (reads) separated in application layer
  - **Commands**: CreateShortURL, UpdateURLMetadata, DeactivateURL, GenerateAPIKey, RevokeAPIKey
  - **Queries**: GetURLByShortCode, ListUserURLs, GetAnalyticsSummary, GetAPIKeyList
  - Handlers orchestrate domain logic, call repositories, publish events
  
- [x] **Infrastructure Adapters** (Principle III): External dependencies (DB, HTTP, cache) implemented as adapters
  - PostgresURLRepository implements domain.URLRepository
  - RedisCache implements domain.CacheStore
  - ZitadelAuthProvider validates JWT tokens, extracts user claims
  - TimescaleAnalyticsRepository implements domain.AnalyticsStore
  - HTTP handlers map requests to commands/queries via DTOs
  
- [x] **Testing Strategy** (Principle IV): Integration/contract tests planned for service boundaries
  - API service: Contract tests for HTTP endpoints (OpenAPI validation)
  - Redirector service: Integration tests with Redis + PostgreSQL
  - Analytics processor: Event processing integration tests
  - Inter-service: Contract tests for event schemas (click events)
  
- [x] **Observability** (Principle V): Structured logging, health checks, caching strategy defined
  - Structured JSON logs with request IDs, user IDs, trace context
  - Health checks: `/health` for each service (DB, Redis, dependencies)
  - Multi-tier caching: L1 in-memory (LRU, 10K entries), L2 Redis (1M entries, 1hr TTL)
  - Metrics: Prometheus endpoints for latency, cache hit rates, event throughput
  
- [x] **Technology Compliance** (Technical Standards): Uses approved stack or justifies new additions
  - Go + Rust match constitution's stack (Go for API, Rust for redirector from project history)
  - PostgreSQL + Redis/Valkey approved in constitution
  - TimescaleDB justified (extension of PostgreSQL, optimized for time-series)
  - TanStack Start justified (user specified "Only frontend is tanstack start")
  
- [x] **Complexity Justification** (Governance): If violations, documented in Complexity Tracking table below
  - **Three services** (API, Redirector, Analytics Processor) justified in Complexity Tracking

**Result**: ⚠️ NEEDS JUSTIFICATION (3-service architecture requires complexity justification)

## Project Structure

### Documentation (this feature)

```text
specs/016-authenticated-url-shortener/
├── plan.md              # This file (/speckit.plan command output)
├── research.md          # Phase 0 output (technology decisions)
├── data-model.md        # Phase 1 output (entities, schemas)
├── quickstart.md        # Phase 1 output (setup guide)
├── contracts/           # Phase 1 output (API contracts)
│   ├── api-service.openapi.yaml
│   ├── events.schema.json
│   └── redirector-service.openapi.yaml
├── checklists/
│   └── requirements.md  # Quality checklist
└── spec.md              # Feature specification
```

### Source Code (repository root)

This is a **distributed web application** with multiple services. Following Refract Constitution and project history (previous Go API + Rust redirector implementation):

```text
services/
├── api/                          # Go - URL management API
│   ├── cmd/api/
│   │   └── main.go               # Entry point, dependency injection
│   ├── internal/
│   │   ├── domain/url/           # Domain layer (Principle I)
│   │   │   ├── entity.go         # URL aggregate root
│   │   │   ├── short_code.go    # ShortCode value object (Snowflake+Base62)
│   │   │   ├── repository.go    # URLRepository interface
│   │   │   └── errors.go         # Domain errors
│   │   ├── domain/apikey/
│   │   │   ├── entity.go         # APIKey aggregate
│   │   │   ├── repository.go    # APIKeyRepository interface
│   │   │   └── hash.go           # BLAKE2 hashing logic
│   │   ├── application/          # CQRS handlers (Principle II)
│   │   │   ├── commands/
│   │   │   │   ├── create_url.go
│   │   │   │   ├── update_url.go
│   │   │   │   ├── generate_api_key.go
│   │   │   │   └── revoke_api_key.go
│   │   │   └── queries/
│   │   │       ├── get_url.go
│   │   │       ├── list_urls.go
│   │   │       └── get_analytics.go
│   │   ├── infrastructure/       # Adapters (Principle III)
│   │   │   ├── persistence/
│   │   │   │   └── postgres/
│   │   │   │       ├── url_repository.go
│   │   │   │       ├── apikey_repository.go
│   │   │   │       └── migrations/
│   │   │   ├── cache/
│   │   │   │   ├── redis_cache.go
│   │   │   │   └── memory_cache.go
│   │   │   ├── auth/
│   │   │   │   └── zitadel_provider.go    # JWT validation
│   │   │   ├── idgen/
│   │   │   │   └── snowflake_generator.go
│   │   │   └── http/
│   │   │       ├── handlers/
│   │   │       ├── middleware/
│   │   │       └── dto/
│   │   └── config/
│   │       └── config.go
│   ├── go.mod
│   ├── go.sum
│   └── Dockerfile
│
├── redirector/                   # Rust - High-performance redirect service
│   ├── src/
│   │   ├── main.rs               # Axum server setup
│   │   ├── handlers/
│   │   │   └── redirect.rs       # GET /:shortCode handler
│   │   ├── cache/
│   │   │   ├── memory.rs         # L1 in-memory LRU cache
│   │   │   └── redis.rs          # L2 Redis cache
│   │   ├── repository/
│   │   │   └── postgres.rs       # Cold miss fallback
│   │   ├── events/
│   │   │   └── publisher.rs      # Publish click events to Redis Stream
│   │   └── config.rs
│   ├── Cargo.toml
│   ├── Cargo.lock
│   └── Dockerfile
│
└── analytics-processor/          # Go - Real-time analytics aggregation
    ├── cmd/processor/
    │   └── main.go               # Event consumer
    ├── internal/
    │   ├── consumer/
    │   │   └── click_events.go   # Redis Stream consumer
    │   ├── aggregator/
    │   │   └── timeseries.go     # Aggregate to hourly/daily buckets
    │   └── repository/
    │       └── timescale_repository.go
    ├── go.mod
    └── Dockerfile

frontend/                         # TanStack Start (official scaffold structure)
├── app/
│   ├── routes/                   # File-based routing
│   │   ├── __root.tsx            # Root layout
│   │   ├── index.tsx             # Landing page (/)
│   │   ├── dashboard.tsx         # URL list (/dashboard)
│   │   ├── create.tsx            # URL creation form (/create)
│   │   ├── analytics.$id.tsx     # Analytics detail page (/analytics/:id)
│   │   └── settings/
│   │       └── api-keys.tsx      # API key management (/settings/api-keys)
│   ├── components/
│   │   ├── URLList.tsx
│   │   ├── AnalyticsCharts.tsx   # Recharts visualizations
│   │   └── AuthGuard.tsx         # Zitadel OIDC integration
│   ├── utils/
│   │   ├── api-client.ts         # Fetch wrapper for API service
│   │   └── auth.ts               # Zitadel OIDC hooks
│   └── router.tsx                # Router configuration
├── public/                       # Static assets
├── package.json
├── tsconfig.json
├── vite.config.ts                # TanStack Start uses Vite
└── Dockerfile

migrations/
└── postgres/
    ├── 00001_create_users.sql
    ├── 00002_create_urls.sql
    ├── 00003_create_api_keys.sql
    └── 00004_create_timescale_hypertables.sql

docker-compose.yml                # Local development environment
                                  # Note: Zitadel NOT included (references external instance via env vars)
                                  # Services: PostgreSQL, TimescaleDB, Redis, API, Redirector, Analytics Processor, Frontend
justfile                          # Development commands (just up, just test, just migrate)
```

**Structure Decision**: 

Chose **distributed web application architecture** (3 services + frontend) based on:
- **Specification requirements**: "Distributed system" (explicit requirement)
- **Performance constraints**: <50ms redirect latency requires dedicated high-performance service
- **Scalability**: Independent scaling of read-heavy (redirector) vs write-heavy (API) vs batch (analytics) workloads
- **Constitution alignment**: Follows project history pattern (previous codebase had Go API + Rust redirector)
- **Technology fit**: Rust optimized for redirect hot path, Go suitable for CRUD API and event processing

Services communicate via:
- **API ← Frontend**: HTTPS REST API
- **Redirector → Analytics**: Redis Streams (async click events)
- **Redirector ↔ Cache**: Redis for L2, in-memory for L1
- **All Services → PostgreSQL/TimescaleDB**: Direct database connections (connection pooling)

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
| **Three services** (API, Redirector, Analytics) instead of monolith | **Performance**: Redirector must handle 10K concurrent requests with <50ms p95 latency. Rust's zero-cost abstractions and async runtime (Tokio) achieve this where Go's GC introduces unpredictable latency spikes.<br><br>**Scalability**: Redirect traffic (read-heavy, 95% of requests) needs independent horizontal scaling from API (write-heavy, complex business logic).<br><br>**Blast Radius**: Redirector is mission-critical (99.9% uptime requirement). Isolating it prevents API bugs from affecting core redirect functionality.<br><br>**Analytics Processing**: Asynchronous batch aggregation (FR-049) naturally decouples from synchronous API operations. | **Monolithic Go API**: Single Go service cannot meet <50ms p95 under 10K concurrent load (GC pauses). Tested in previous implementation (commit 9d1337a).<br><br>**Two services** (API+Redirector, analytics in API): Analytics batch jobs would compete with API request threads for resources, degrading API latency. Event processing requires different scaling profile (CPU-intensive aggregations vs I/O-bound API). |
| **TimescaleDB** (PostgreSQL extension) in addition to PostgreSQL | **Analytics Performance**: 10M events/month with 5-year retention = 600M+ rows. Time-series queries (hourly/daily aggregations, date range filters) on standard PostgreSQL tables require full table scans.<br><br>**Automatic Partitioning**: TimescaleDB hypertables auto-partition by time, enabling efficient pruning for date range queries.<br><br>**Compression**: Native columnar compression reduces storage by 90% for historical data.<br><br>**Continuou

s Aggregates**: Materialized views auto-refresh for dashboard queries (FR-024: 5-second real-time requirement). | **PostgreSQL only**: Manual partitioning complex and error-prone. No native time-series optimizations. Aggregation queries exceed 5-second requirement at scale.<br><br>**Separate ClickHouse**: Operational complexity of managing second database cluster. TimescaleDB is PostgreSQL extension (single cluster, same tooling). |

**Constitution Compliance Verdict**: ✅ **PASS WITH JUSTIFICATION**

Complexity additions are justified by:
1. **Hard performance requirements** (FR-016: <50ms p95)
2. **Explicit specification** ("Distributed system", FR-047)
3. **Scale requirements** (10M events/month, FR-024: 5-second analytics)
4. **Proven pattern** (matches previous implementation architecture)

